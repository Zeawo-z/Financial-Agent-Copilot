import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.tools import tool


# ==========================================
# 1. ä½¿ç”¨ç±»ä½œä¸ºå®¹å™¨ï¼Œå½»åº•é¿å… NameError
# ==========================================
class RAGStorage:
    """
    ä¸€ä¸ªç®€å•çš„å®¹å™¨ç±»ï¼Œç”¨æ¥å­˜æ”¾å‘é‡åº“å’Œæ¨¡å‹ã€‚
    è¿™æ · Python æ°¸è¿œèƒ½é€šè¿‡ RAGStorage.vector_store æ‰¾åˆ°å®ƒã€‚
    """
    vector_store = None
    embeddings = None
    db_path = "faiss_index_db"


# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘å‡½æ•°
# ==========================================

def get_embeddings():
    """è·å–æˆ–åˆå§‹åŒ– Embedding æ¨¡å‹"""
    if RAGStorage.embeddings is None:
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– Embedding æ¨¡å‹...")
        try:
            RAGStorage.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2"
            )
        except Exception as e:
            print(f"âŒ Embedding åŠ è½½å¤±è´¥: {e}")
            raise e
    return RAGStorage.embeddings


def load_vector_store():
    """å°è¯•åŠ è½½çŸ¥è¯†åº“"""
    # 1. å¦‚æœå†…å­˜é‡Œå·²ç»æœ‰äº†ï¼Œç›´æ¥è¿”å›
    if RAGStorage.vector_store is not None:
        return RAGStorage.vector_store

    # 2. å¦‚æœç¡¬ç›˜ä¸Šæœ‰å­˜æ¡£ï¼ŒåŠ è½½å®ƒ
    if os.path.exists(RAGStorage.db_path):
        print(f"ğŸ“‚ æ£€æµ‹åˆ°æœ¬åœ°å­˜æ¡£ {RAGStorage.db_path}ï¼Œæ­£åœ¨åŠ è½½...")
        try:
            emb = get_embeddings()
            RAGStorage.vector_store = FAISS.load_local(
                RAGStorage.db_path,
                emb,
                allow_dangerous_deserialization=True
            )
            print("âœ… çŸ¥è¯†åº“åŠ è½½æˆåŠŸï¼")
            return RAGStorage.vector_store
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å­˜æ¡£å¤±è´¥: {e}")
            return None
    return None


def initialize_knowledge_base(file_path):
    """æ„å»ºå¹¶ä¿å­˜çŸ¥è¯†åº“"""
    try:
        emb = get_embeddings()
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {file_path}...")

        loader = PyPDFLoader(file_path)
        docs = loader.load()

        if not docs:
            return False

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        splits = text_splitter.split_documents(docs)

        print("ğŸ§  æ„å»º FAISS ç´¢å¼•...")
        # ç›´æ¥å­˜å…¥ç±»å±æ€§ä¸­
        RAGStorage.vector_store = FAISS.from_documents(splits, emb)

        print(f"ğŸ’¾ ä¿å­˜åˆ°ç¡¬ç›˜...")
        RAGStorage.vector_store.save_local(RAGStorage.db_path)

        print("âœ… çŸ¥è¯†åº“å¤„ç†å®Œæ¯•ï¼")
        return True
    except Exception as e:
        print(f"âŒ æ„å»ºå¤±è´¥: {e}")
        return False


# ==========================================
# 3. å·¥å…·å®šä¹‰
# ==========================================

@tool("knowledge_base_tool")
def knowledge_base_tool(query: str):
    """
    åªæœ‰å½“ç”¨æˆ·è¯¢é—®å…³äº'ä¸Šä¼ æ–‡æ¡£'ã€'çŸ¥è¯†åº“'ã€'è¿™ç¯‡æŠ¥å‘Š'æˆ–'æ–‡ä»¶'ç›¸å…³å†…å®¹æ—¶ï¼Œæ‰ä½¿ç”¨æ­¤å·¥å…·ã€‚
    """
    # 1. è‡ªåŠ¨å°è¯•åŠ è½½
    db = load_vector_store()

    if db is None:
        return "å½“å‰çŸ¥è¯†åº“ä¸ºç©ºã€‚è¯·å…ˆä¸Šä¼  PDF æ–‡æ¡£ã€‚"

    try:
        # 2. æ£€ç´¢
        retriever = db.as_retriever(search_kwargs={"k": 3})
        docs = retriever.invoke(query)

        if not docs:
            return "çŸ¥è¯†åº“é‡Œæ²¡æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

        # 3. ç»“æœæ‹¼æ¥
        context = "\n\n".join([d.page_content for d in docs])
        return f"ã€ä»æ–‡æ¡£ä¸­æœç´¢åˆ°çš„å†…å®¹ã€‘ï¼š\n{context}"
    except Exception as e:
        return f"æ£€ç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"