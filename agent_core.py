import asyncio
from typing import AsyncIterable, Any, Union

from langchain.agents import AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.tools import tool, render_text_description
from langchain_community.tools.ddg_search.tool import DuckDuckGoSearchRun
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from pydantic import BaseModel, Field
from dotenv import load_dotenv

# â¬‡ï¸ æ ¸å¿ƒä¿®å¤ï¼šå¯¼å…¥å¿…è¦çš„æ ¼å¼åŒ–å·¥å…·å’Œé“¾å¼å·¥å…·
from langchain.agents.format_scratchpad import format_log_to_str
from langchain_core.runnables import RunnablePassthrough
from langchain.agents.output_parsers import ReActSingleInputOutputParser
from langchain_core.agents import AgentAction, AgentFinish

# å¯¼å…¥å·¥å…·å‡½æ•°
from tools.tool1_å¤©æ°”æŸ¥è¯¢ import get_weather
from tools.tool2_æ—¶é—´è·å– import get_current_time
from tools.tool4_finance import get_stock_data
from tools.tool5_rag import knowledge_base_tool as rag_tool_func
from datetime import datetime
import pytz
load_dotenv()


# ==========================================
# 1. å®šä¹‰å·¥å…· (ä¿æŒä¸å˜)
# ==========================================
class StockInput(BaseModel):
    ticker: str = Field(description="è‚¡ç¥¨ä»£ç ...")


class SearchInput(BaseModel):
    query: str = Field(description="æŸ¥è¯¢å…³é”®è¯")


class WeatherInput(BaseModel):
    city: str = Field(description="åŸå¸‚åç§°...")


@tool("stock_tool", args_schema=StockInput)
def stock_tool(ticker: str):
    """
    æŸ¥è¯¢è‚¡ç¥¨çš„å®æ—¶ä»·æ ¼ã€å¸‚å€¼ã€PEç­‰åŸºæœ¬é¢æ•°æ®ã€‚
    å¦‚æœä¸çŸ¥é“ä»£ç ï¼Œè¯·å…ˆä½¿ç”¨ search_tool æŸ¥è¯¢ã€‚
    """
    return get_stock_data(ticker)


search = DuckDuckGoSearchRun()


@tool("search_tool", args_schema=SearchInput)
def search_tool(query: str):
    """
    ç”¨äºæœç´¢äº’è”ç½‘ä¸Šçš„å®æ—¶ä¿¡æ¯ï¼š
    1. è‚¡ç¥¨ä»£ç ï¼ˆå¦‚'èŒ…å° è‚¡ç¥¨ä»£ç 'ï¼‰
    2. è¿‘æœŸè´¢ç»æ–°é—»ï¼ˆå¦‚'Tesla latest news'ï¼‰
    3. é€šç”¨çŸ¥è¯†æŸ¥è¯¢
    """
    return search.run(query)


@tool("weather_tool", args_schema=WeatherInput)
def weather_tool(city: str):
    """
    è·å–æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ä¿¡æ¯ã€‚
    è¾“å…¥å‚æ•°ä¸ºåŸå¸‚åç§°ï¼ˆå¦‚'æ­å·'ï¼‰ã€‚
    """
    return get_weather(city)


@tool("time_tool")
def time_tool(any_text: str = ""):
    """
    è·å–å½“å‰ç³»ç»Ÿæ—¶é—´ã€‚æ— éœ€è¾“å…¥å‚æ•°ã€‚
    """
    # è§£é‡Šï¼š
    # 1. Agent ä¼šä¼  "" (ç©ºå­—ç¬¦ä¸²)ã€‚
    # 2. æˆ‘ä»¬å®šä¹‰å‚æ•° any_text ä¸º str ç±»å‹ã€‚
    # 3. str å¯¹ strï¼Œç±»å‹å®Œç¾åŒ¹é…ï¼ŒPydantic é—­å˜´ã€‚
    # 4. æˆ‘ä»¬åœ¨å‡½æ•°é‡Œç›´æ¥æ— è§†è¿™ä¸ªå‚æ•°ã€‚

    try:
        tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(tz)
        return f"å½“å‰æ—¶é—´æ˜¯ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')} (æ˜ŸæœŸ{now.isoweekday()})"
    except Exception as e:
        return f"è·å–æ—¶é—´å¤±è´¥: {e}"

knowledge_base_tool = rag_tool_func

tools = [weather_tool, time_tool, search_tool, stock_tool, knowledge_base_tool]
tool_names = [t.name for t in tools]


# ==========================================
# 2. è‡ªå®šä¹‰å®½å®¹è§£æå™¨ (ä¿æŒä¸å˜)
# ==========================================
class LooseReActParser(ReActSingleInputOutputParser):
    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:
        try:
            return super().parse(text)
        except Exception:
            return AgentFinish(
                return_values={"output": text.strip()},
                log=text
            )


# ==========================================
# 3. è®°å¿†ç®¡ç†
# ==========================================
store = {}


def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]


# ==========================================
# 4. Agent åˆå§‹åŒ– (ğŸ”¥ æ ¸å¿ƒä¿®å¤åŒºåŸŸ)
# ==========================================
global_agent = None


def init_agent(model_name="qwen-plus", system_prompt=None):
    global global_agent

    # 1. è®¾ç½® Prompt
    base_template = """
ã€å·¥å…·èƒ½åŠ›ã€‘
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
{tools}

ã€æ€è€ƒæµç¨‹ã€‘
1. é—²èŠ (å¦‚"ä½ å¥½") -> ç›´æ¥å›ç­”ï¼Œä¸è¦ç”¨ Actionã€‚
2. ä»»åŠ¡ (å¦‚"æŸ¥å¤©æ°”") -> ä½¿ç”¨ ReAct æ ¼å¼ï¼š
   Thought: æ€è€ƒ...
   Action: å·¥å…·å (å¿…é¡»æ˜¯ [{tool_names}] ä¹‹ä¸€)
   Action Input: å‚æ•°
   Observation: ...

å¼€å§‹ï¼

Question: {input}
{agent_scratchpad}
    """

    if system_prompt:
        final_template = f"ã€ç³»ç»Ÿè®¾å®šã€‘ï¼š{system_prompt}\n\n" + base_template
    else:
        final_template = "ä½ æ˜¯ä¸€ä½å…¨èƒ½æ™ºèƒ½åŠ©æ‰‹ã€‚\n\n" + base_template

    prompt = PromptTemplate.from_template(final_template).partial(
        tools=render_text_description(tools),
        tool_names=", ".join([t.name for t in tools])
    )

    # 2. åˆå§‹åŒ– LLM
    llm = ChatOpenAI(
        model=model_name,
        temperature=0.1,
        streaming=True,
        max_retries=3,
        model_kwargs={
            "stop": ["\nObservation:", "Observation:"]
        }
    )

    # 3. ğŸ”¥ æ„å»º Agent é“¾ (ä¿®å¤äº† missing variable é—®é¢˜)
    # RunnablePassthrough.assign è´Ÿè´£æŠŠ intermediate_steps è½¬æ¢æˆ agent_scratchpad
    agent = (
            RunnablePassthrough.assign(
                agent_scratchpad=lambda x: format_log_to_str(x["intermediate_steps"])
            )
            | prompt
            | llm
            | LooseReActParser()
    )

    # 4. åˆ›å»ºæ‰§è¡Œå™¨
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        max_iterations=5
    )

    # 5. è®°å¿†åŠŸèƒ½
    agent_with_history = RunnableWithMessageHistory(
        agent_executor,
        get_session_history,
        input_messages_key="input",
        history_messages_key="chat_history",
    )

    global_agent = agent_with_history
    print(f"ğŸ”„ Agent å·²æ›´æ–° | æ¨¡å‹: {model_name}")
    return agent_with_history


# ==========================================
# 5. è¾…åŠ©å‡½æ•°
# ==========================================
init_agent()


def update_agent_settings(model, prompt):
    init_agent(model_name=model, system_prompt=prompt)
    return f"Agent å·²æ›´æ–°ä¸º {model}"


async def get_stream_response(query: str, session_id: str) -> AsyncIterable[str]:
    try:
        async for event in global_agent.astream_events(
                {"input": query},
                config={"configurable": {"session_id": session_id}},
                version="v1",
        ):
            kind = event["event"]
            if kind == "on_chat_model_stream":
                content = event["data"]["chunk"].content
                if content:
                    yield content
    except Exception as e:
        yield f"Final Answer: å‘ç”Ÿé”™è¯¯: {str(e)}"